{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b04b3c",
   "metadata": {},
   "source": [
    "# Introduction to Data Preparation for NYC Taxi Trips\n",
    "\n",
    "## Objective\n",
    "This Jupyter Notebook is dedicated to the initial stage of our data analytics project—**Data Preparation**. The primary goal here is to prepare the vast New York City Taxi Trips dataset for the year 2021, ensuring it's clean, organized, and ready for in-depth analysis and modeling in subsequent stages. The dataset, which includes over 30 million records, requires meticulous handling to manage its volume and enhance its quality effectively.\n",
    "\n",
    "## Background\n",
    "The NYC Taxi Trips dataset is sourced from the NYC Open Data portal and offers a detailed snapshot of taxi activities across New York City. It records every taxi trip's core details, such as times of pickup and dropoff, trip distances, fares charged, and more. These records not only provide insights into the city’s mobility patterns but also serve as a basis for predictive modeling of fares and understanding factors influencing taxi trip dynamics.\n",
    "\n",
    "## Scope of This Notebook\n",
    "In this notebook, we will perform several key tasks to prepare the data for further analysis:\n",
    "1. **Data Loading**: Load the data from four pre-processed partitions to manage the dataset's size efficiently.\n",
    "2. **Initial Exploration**: Conduct a preliminary examination to understand the dataset's structure, missing values, anomalies, and data types.\n",
    "3. **Data Cleaning**: Address missing or incorrect values, remove duplicates, and handle any outliers or erroneous entries.\n",
    "4. **Feature Engineering**: Develop new features that are more informative for analysis and predictive modeling, such as calculating trip durations and categorizing times of day.\n",
    "5. **Data Transformation**: Standardize and normalize data as necessary to prepare for machine learning algorithms that require standardized input.\n",
    "6. **Data Reduction**: Reduce dimensionality where applicable to improve model performance and decrease computational requirements.\n",
    "\n",
    "## Tools and Libraries\n",
    "We will use Python as our main programming language, leveraging libraries such as Pandas for data manipulation, Numpy for numerical operations, and Matplotlib/Seaborn for visualization purposes. These tools are chosen for their efficiency and ease of use in handling large datasets like ours.\n",
    "\n",
    "## Conclusion\n",
    "By the end of this notebook, the dataset will be transformed into a clean, comprehensive format suitable for detailed exploratory data analysis and machine learning tasks in the following stages of this project. The meticulous preparation we perform here is crucial for ensuring the accuracy and reliability of our later analyses and predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3fb64",
   "metadata": {},
   "source": [
    "# 1. Data Loading \n",
    "In this section we import all necessary libraries and datasets for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d38c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set some options for displaying the data tables nicely\n",
    "pd.set_option('display.max_columns', None)  # Show all columns of DataFrames\n",
    "pd.set_option('display.width', 1000)        # Ensure the display is wide enough to view all DataFrame columns\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)  # Format floats for easier reading\n",
    "\n",
    "# Setting the style for seaborn plots\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab060a",
   "metadata": {},
   "source": [
    "Pickle is a Python-specific binary serialization method used to save and load Python objects directly, preserving their data types and structure. In our NYC Taxi Trips data analytics project, we chose Pickle for its efficiency and ease of use, especially given the large volume of data involved. It enables fast loading and saving of complex Pandas DataFrames, significantly speeding up our workflow by avoiding repeated preprocessing. Although Pickle should be used cautiously due to security risks when dealing with untrusted data sources, it is ideal for our controlled environment where these concerns are mitigated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc76e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from Pickle files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define data types for data consistency\n",
    "dtypes = {\n",
    "    'VendorID': 'category',\n",
    "    'tpep_pickup_datetime': 'str',\n",
    "    'tpep_dropoff_datetime': 'str',\n",
    "    'passenger_count': 'float64',\n",
    "    'trip_distance': 'float64',\n",
    "    'RatecodeID': 'category',\n",
    "    'store_and_fwd_flag': 'category',\n",
    "    'PULocationID': 'category',\n",
    "    'DOLocationID': 'category',\n",
    "    'payment_type': 'category',\n",
    "    'fare_amount': 'float64',\n",
    "    'extra': 'float64',\n",
    "    'mta_tax': 'float64',\n",
    "    'tip_amount': 'float64',\n",
    "    'tolls_amount': 'float64',\n",
    "    'improvement_surcharge': 'float64',\n",
    "    'total_amount': 'float64',\n",
    "    'congestion_surcharge': 'float64'\n",
    "}\n",
    "\n",
    "# Load data from CSV files only if Pickle files do not exist or when processing for the first time\n",
    "try:\n",
    "    df1 = pd.read_pickle(\"/Users/md/Desktop/python_project/df1.pkl\")\n",
    "    df2 = pd.read_pickle(\"/Users/md/Desktop/python_project/df2.pkl\")\n",
    "    df3 = pd.read_pickle(\"/Users/md/Desktop/python_project/df3.pkl\")\n",
    "    df4 = pd.read_pickle(\"/Users/md/Desktop/python_project/df4.pkl\")\n",
    "    print(\"Data loaded from Pickle files.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Pickle files not found. Loading data from CSV files and saving as Pickle.\")\n",
    "    df1 = pd.read_csv(\"2021_TLC_0.csv\", dtype=dtypes)\n",
    "    df2 = pd.read_csv(\"2021_TLC_1.csv\", dtype=dtypes)\n",
    "    df3 = pd.read_csv(\"2021_TLC_2.csv\", dtype=dtypes)\n",
    "    df4 = pd.read_csv(\"2021_TLC_3.csv\", dtype=dtypes)\n",
    "    # Save DataFrames to Pickle for future use\n",
    "    df1.to_pickle(\"/Users/md/Desktop/python_project/df1.pkl\")\n",
    "    df2.to_pickle(\"/Users/md/Desktop/python_project/df2.pkl\")\n",
    "    df3.to_pickle(\"/Users/md/Desktop/python_project/df3.pkl\")\n",
    "    df4.to_pickle(\"/Users/md/Desktop/python_project/df4.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52803b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
       "0      1.0  2021-01-01 00:30:10   2021-01-01 00:36:12             1.00           2.10        1.0                  N        142.0         43.0          2.0         8.00   3.00     0.50        0.00          0.00                   0.30         11.80                  2.50\n",
       "1      1.0  2021-01-01 00:51:20   2021-01-01 00:52:19             1.00           0.20        1.0                  N        238.0        151.0          2.0         3.00   0.50     0.50        0.00          0.00                   0.30          4.30                  0.00\n",
       "2      1.0  2021-01-01 00:43:30   2021-01-01 01:11:06             1.00          14.70        1.0                  N        132.0        165.0          1.0        42.00   0.50     0.50        8.65          0.00                   0.30         51.95                  0.00\n",
       "3      1.0  2021-01-01 00:15:48   2021-01-01 00:31:01             0.00          10.60        1.0                  N        138.0        132.0          1.0        29.00   0.50     0.50        6.05          0.00                   0.30         36.35                  0.00\n",
       "4      2.0  2021-01-01 00:31:49   2021-01-01 00:48:21             1.00           4.94        1.0                  N         68.0         33.0          1.0        16.50   0.50     0.50        4.06          0.00                   0.30         24.36                  2.50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcf395",
   "metadata": {},
   "source": [
    "In the section above we loaded all 4 partitioned datasets for analysis defined data types based on the documentation for the dataset. We then loaded the Dataframes into pickle format for faster processing and for the purpose of tracking and maintaining consistency throughout rest of the notebook without the need to load large CSV files into df after every launch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708ed2e",
   "metadata": {},
   "source": [
    "# 2. Initial Exploration\n",
    "\n",
    "After loading the data, it's crucial to understand its structure, identify any missing values, spot potential anomalies, and review the data types. We start by exploring one of the DataFrames:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0aa9a",
   "metadata": {},
   "source": [
    "### Partition 1 Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c3e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "0      1.0  2021-01-01 00:30:10   2021-01-01 00:36:12             1.00           2.10        1.0                  N        142.0         43.0          2.0         8.00   3.00     0.50        0.00          0.00                   0.30         11.80                  2.50\n",
      "1      1.0  2021-01-01 00:51:20   2021-01-01 00:52:19             1.00           0.20        1.0                  N        238.0        151.0          2.0         3.00   0.50     0.50        0.00          0.00                   0.30          4.30                  0.00\n",
      "2      1.0  2021-01-01 00:43:30   2021-01-01 01:11:06             1.00          14.70        1.0                  N        132.0        165.0          1.0        42.00   0.50     0.50        8.65          0.00                   0.30         51.95                  0.00\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7919804 entries, 0 to 7919803\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               category      \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             category      \n",
      " 6   store_and_fwd_flag     category      \n",
      " 7   PULocationID           category      \n",
      " 8   DOLocationID           category      \n",
      " 9   payment_type           category      \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      "dtypes: category(6), datetime64[ns](2), float64(10)\n",
      "memory usage: 785.5 MB\n",
      "None\n",
      "       passenger_count  trip_distance  fare_amount        extra      mta_tax   tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "count     7,467,266.00   7,919,804.00 7,919,804.00 7,919,804.00 7,919,804.00 7,919,804.00  7,919,804.00           7,919,804.00  7,919,804.00          7,919,804.00\n",
      "mean              1.41           5.02        12.36         1.05         0.49         2.00          0.25                   0.30         17.96                  2.17\n",
      "std               1.03         497.23       199.96         1.26         0.07         2.45          1.43                   0.04        200.07                  0.87\n",
      "min               0.00           0.00      -643.50        -5.50        -0.50      -333.32        -38.02                  -0.30       -647.80                 -2.50\n",
      "25%               1.00           1.01         6.50         0.00         0.50         0.00          0.00                   0.30         11.16                  2.50\n",
      "50%               1.00           1.71         9.00         0.50         0.50         1.86          0.00                   0.30         14.16                  2.50\n",
      "75%               1.00           3.04        13.50         2.50         0.50         2.76          0.00                   0.30         19.56                  2.50\n",
      "max               9.00     280,567.84   398,466.38        90.06         3.85     1,140.44        811.75                   0.30    398,469.20                  3.00\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the first DataFrame\n",
    "print(df1.head(3))\n",
    "\n",
    "# Display summary information about DataFrame\n",
    "print(df1.info())\n",
    "\n",
    "# Basic statistical details\n",
    "print(df1.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee91e44",
   "metadata": {},
   "source": [
    "The output from your DataFrame `df1` provides a snapshot of the NYC Taxi Trips dataset for 2021, along with a detailed summary and structure of the data. Here's an analysis of the provided output:\n",
    "\n",
    "### Data Structure and Content Overview:\n",
    "- **Rows and Columns:** The DataFrame contains approximately 7,919,804 entries across 18 different attributes (columns), suggesting a substantial amount of taxi trip data.\n",
    "- **Data Types:** \n",
    "  - **Categorical Data:** Columns like `VendorID`, `RatecodeID`, `store_and_fwd_flag`, `PULocationID`, `DOLocationID`, and `payment_type` are stored as categories, which is efficient for columns with a limited number of unique values.\n",
    "  - **Datetime Data:** The pickup and dropoff times (`tpep_pickup_datetime` and `tpep_dropoff_datetime`) are appropriately stored as `datetime64[ns]`, facilitating time series analysis.\n",
    "  - **Numerical Data:** Attributes like `passenger_count`, `trip_distance`, `fare_amount`, and other cost-related fields are stored as `float64`, suitable for calculations and statistical analysis.\n",
    "\n",
    "### Statistical Summary:\n",
    "- **Central Tendency and Distribution:**\n",
    "  - **`passenger_count`** shows an average of 1.41 passengers per trip, with most trips carrying just 1 passenger.\n",
    "  - **`trip_distance`** has an average of 5.02 miles, but the standard deviation and the maximum value suggest extreme outliers (max 280,567.84 miles).\n",
    "  - **`fare_amount`** has an average of has an average of 12.36, but similar to trip distance,the standard deviation and maximum suggest significant outliers or possible data entry errors (max $398,466.38).\n",
    "  \n",
    "- **Anomalies/Outliers:** \n",
    "  - The presence of negative values in `fare_amount`, `extra`, `mta_tax`, `tip_amount`, `tolls_amount`, `improvement_surcharge`, `total_amount`, and `congestion_surcharge` might indicate refunds, data entry errors, or other anomalies.\n",
    "  - Extremely high maximum values in `trip_distance`, `fare_amount`, `tip_amount`, and `total_amount` could be due to erroneous entries or rare, very long trips.\n",
    "\n",
    "### Potential Data Quality Issues:\n",
    "- **Outliers and Errors:** As noted, the presence of extreme values and negative amounts could affect the integrity of analyses and models if not addressed.\n",
    "- **Missing Values:** Any NaNs or nulls in the dataset would need to be identified and handled appropriately during data cleaning.\n",
    "\n",
    "### Suggested Next Steps:\n",
    "1. **Data Cleaning:** Address outliers and errors, possibly by removing or capping values based on reasonable thresholds or business understanding.\n",
    "2. **Handling Missing Values:** If any missing values are identified (which should be checked explicitly), determine the best strategy for handling them—either through imputation or removal, depending on the context.\n",
    "3. **Feature Engineering:** Consider deriving new features, such as trip duration, hour of the day, day of the week, which might be useful for further analysis and predictive modeling.\n",
    "4. **Deeper Exploration:** Further exploratory data analysis would be beneficial to understand relationships between variables, especially how categorical features relate to fare and distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d11860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " VendorID                 452538\n",
      "tpep_pickup_datetime          0\n",
      "tpep_dropoff_datetime         0\n",
      "passenger_count          452538\n",
      "trip_distance                 0\n",
      "RatecodeID               452538\n",
      "store_and_fwd_flag       452538\n",
      "PULocationID                  0\n",
      "DOLocationID                  0\n",
      "payment_type             452538\n",
      "fare_amount                   0\n",
      "extra                         0\n",
      "mta_tax                       0\n",
      "tip_amount                    0\n",
      "tolls_amount                  0\n",
      "improvement_surcharge         0\n",
      "total_amount                  0\n",
      "congestion_surcharge          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_values1 = df1.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564137f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Analysis of Missing Values\n",
    "\n",
    "Several columns in your DataFrame have the exact same number of missing values (452,538), suggesting a pattern or potential issue during data collection or extraction. The affected columns are:\n",
    "\n",
    "- **`VendorID`**\n",
    "- **`passenger_count`**\n",
    "- **`RatecodeID`**\n",
    "- **`store_and_fwd_flag`**\n",
    "- **`payment_type`**\n",
    "\n",
    "Given that none of the monetary or distance-related columns (`fare_amount`, `trip_distance`, `total_amount`, etc.) have missing values, the missing data is restricted to categorical and count data, which could impact analyses that depend on these dimensions, such as demographic studies or rate code analysis.\n",
    "\n",
    "##### Suggested Handling Strategies\n",
    "\n",
    "1. **Understanding the Context:**\n",
    "   - **Determine the Cause:** Before deciding on a handling strategy, investigate why these values are missing. Is it a systematic error, data corruption, or are they missing at random? This might involve checking back with the data source or reviewing the data extraction and loading logs.\n",
    "   - **Impact Assessment:** Evaluate how critical these columns are to your analysis or models. For instance, if `VendorID` or `payment_type` plays a significant role in your analysis, more sophisticated methods of imputation might be necessary.\n",
    "\n",
    "2. **Deletion:**\n",
    "   - **Remove Rows:** If the missing data represents a small proportion of the total dataset and is not systematically biased, you might consider dropping these rows.\n",
    "   - **Remove Columns:** If a column has a significant number of missing values that cannot be imputed accurately and is not critical, consider dropping the column.\n",
    "\n",
    "3. **Imputation:**\n",
    "   - **Categorical Imputation:** For categorical fields like `VendorID`, `RatecodeID`, `store_and_fwd_flag`, and `payment_type`, you can impute missing values using the mode (the most frequently occurring value in each column) or employ predictive imputation methods (e.g., classification algorithms if patterns can be discerned from other data).\n",
    "   - **Count Imputation:** For `passenger_count`, consider using median values for imputation, as mean might be skewed by outliers. Alternatively, use a model-based approach if the missing data pattern suggests dependency on other variables (e.g., trip distance, fare amount).\n",
    "\n",
    "4. **Advanced Techniques:**\n",
    "   - **Predictive Modeling:** Use machine learning models to predict missing values based on other variables in the dataset.\n",
    "   - **Multiple Imputation:** Multiple imputation techniques can be used for handling missing data in a way that reflects the uncertainty about the right approach to impute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc440887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      " VendorID                       category\n",
      "tpep_pickup_datetime     datetime64[ns]\n",
      "tpep_dropoff_datetime    datetime64[ns]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                     category\n",
      "store_and_fwd_flag             category\n",
      "PULocationID                   category\n",
      "DOLocationID                   category\n",
      "payment_type                   category\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of each column:\\n\", df1.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10da00",
   "metadata": {},
   "source": [
    "### Partition 2 Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a4a798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "0      2.0  05/15/2021 10:35:13 AM  05/15/2021 11:08:19 AM             5.00          17.89        2.0                  N        132.0        224.0          1.0        52.00   0.00     0.50        8.00          6.55                   0.30         69.85                  2.50\n",
      "1      2.0  05/15/2021 10:13:57 AM  05/15/2021 10:19:57 AM             2.00           1.11        1.0                  N        114.0        249.0          1.0         6.50   0.00     0.50        1.96          0.00                   0.30         11.76                  2.50\n",
      "2      2.0  05/15/2021 10:26:33 AM  05/15/2021 10:43:56 AM             2.00           4.44        1.0                  N        100.0         12.0          1.0        16.50   0.00     0.50        3.96          0.00                   0.30         23.76                  2.50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7887665 entries, 0 to 7887664\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   VendorID               category\n",
      " 1   tpep_pickup_datetime   object  \n",
      " 2   tpep_dropoff_datetime  object  \n",
      " 3   passenger_count        float64 \n",
      " 4   trip_distance          float64 \n",
      " 5   RatecodeID             category\n",
      " 6   store_and_fwd_flag     category\n",
      " 7   PULocationID           category\n",
      " 8   DOLocationID           category\n",
      " 9   payment_type           category\n",
      " 10  fare_amount            float64 \n",
      " 11  extra                  float64 \n",
      " 12  mta_tax                float64 \n",
      " 13  tip_amount             float64 \n",
      " 14  tolls_amount           float64 \n",
      " 15  improvement_surcharge  float64 \n",
      " 16  total_amount           float64 \n",
      " 17  congestion_surcharge   float64 \n",
      "dtypes: category(6), float64(10), object(2)\n",
      "memory usage: 782.3+ MB\n",
      "None\n",
      "       passenger_count  trip_distance  fare_amount        extra      mta_tax   tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "count     7,506,175.00   7,887,665.00 7,887,665.00 7,887,665.00 7,887,665.00 7,887,665.00  7,887,665.00           7,887,665.00  7,887,665.00          7,887,665.00\n",
      "mean              1.45           7.91        13.46         1.04         0.49         2.32          0.39                   0.30         19.63                  2.24\n",
      "std               1.06         780.95        12.57         1.25         0.08         2.79          1.90                   0.04         15.21                  0.79\n",
      "min               0.00           0.00      -624.00        -5.50        -0.50      -130.10        -34.05                  -0.30       -627.80                 -2.50\n",
      "25%               1.00           1.10         6.50         0.00         0.50         0.00          0.00                   0.30         11.76                  2.50\n",
      "50%               1.00           1.85         9.50         0.50         0.50         2.00          0.00                   0.30         15.20                  2.50\n",
      "75%               2.00           3.36        15.00         2.50         0.50         3.00          0.00                   0.30         21.23                  2.50\n",
      "max             112.00     332,541.19     1,320.00        45.50         4.55       449.21        956.55                   0.30      1,320.80                  2.75\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the first DataFrame\n",
    "print(df2.head(3))\n",
    "\n",
    "# Display summary information about DataFrame\n",
    "print(df2.info())\n",
    "\n",
    "# Basic statistical details\n",
    "print(df2.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee21f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " VendorID                 381490\n",
      "tpep_pickup_datetime          0\n",
      "tpep_dropoff_datetime         0\n",
      "passenger_count          381490\n",
      "trip_distance                 0\n",
      "RatecodeID               381490\n",
      "store_and_fwd_flag       381490\n",
      "PULocationID                  0\n",
      "DOLocationID                  0\n",
      "payment_type             381490\n",
      "fare_amount                   0\n",
      "extra                         0\n",
      "mta_tax                       0\n",
      "tip_amount                    0\n",
      "tolls_amount                  0\n",
      "improvement_surcharge         0\n",
      "total_amount                  0\n",
      "congestion_surcharge          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_values2 = df2.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5c9781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      " VendorID                 category\n",
      "tpep_pickup_datetime       object\n",
      "tpep_dropoff_datetime      object\n",
      "passenger_count           float64\n",
      "trip_distance             float64\n",
      "RatecodeID               category\n",
      "store_and_fwd_flag       category\n",
      "PULocationID             category\n",
      "DOLocationID             category\n",
      "payment_type             category\n",
      "fare_amount               float64\n",
      "extra                     float64\n",
      "mta_tax                   float64\n",
      "tip_amount                float64\n",
      "tolls_amount              float64\n",
      "improvement_surcharge     float64\n",
      "total_amount              float64\n",
      "congestion_surcharge      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of each column:\\n\", df2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e867d",
   "metadata": {},
   "source": [
    "### Partition 2 Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986e34a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "0      1.0  08/10/2021 04:22:40 PM  08/10/2021 04:40:02 PM             1.00           2.50        1.0                  N        170.0        236.0          1.0        13.00   3.50     0.50        3.45          0.00                   0.30         20.75                  2.50\n",
      "1      1.0  08/10/2021 04:11:09 PM  08/10/2021 04:19:01 PM             0.00           1.00        1.0                  N        107.0         90.0          2.0         7.00   3.50     0.50        0.00          0.00                   0.30         11.30                  2.50\n",
      "2      1.0  08/10/2021 04:20:56 PM  08/10/2021 04:35:54 PM             0.00           2.40        1.0                  N         68.0        142.0          1.0        11.50   3.50     0.50        3.15          0.00                   0.30         18.95                  2.50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7873284 entries, 0 to 7873283\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   VendorID               category\n",
      " 1   tpep_pickup_datetime   object  \n",
      " 2   tpep_dropoff_datetime  object  \n",
      " 3   passenger_count        float64 \n",
      " 4   trip_distance          float64 \n",
      " 5   RatecodeID             category\n",
      " 6   store_and_fwd_flag     category\n",
      " 7   PULocationID           category\n",
      " 8   DOLocationID           category\n",
      " 9   payment_type           category\n",
      " 10  fare_amount            float64 \n",
      " 11  extra                  float64 \n",
      " 12  mta_tax                float64 \n",
      " 13  tip_amount             float64 \n",
      " 14  tolls_amount           float64 \n",
      " 15  improvement_surcharge  float64 \n",
      " 16  total_amount           float64 \n",
      " 17  congestion_surcharge   float64 \n",
      "dtypes: category(6), float64(10), object(2)\n",
      "memory usage: 780.9+ MB\n",
      "None\n",
      "       passenger_count  trip_distance  fare_amount        extra      mta_tax   tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "count     7,594,840.00   7,873,284.00 7,873,284.00 7,873,284.00 7,873,284.00 7,873,284.00  7,873,284.00           7,873,284.00  7,873,284.00          7,594,840.00\n",
      "mean              1.42           6.02        13.99         1.05         0.49         2.48          0.43                   0.30         20.39                  2.30\n",
      "std               1.03         579.71       291.91         1.25         0.08         2.93          1.89                   0.04        292.05                  0.71\n",
      "min               0.00           0.00      -758.00        -5.50        -0.50      -200.00        -88.75                  -0.30       -951.00                 -2.50\n",
      "25%               1.00           1.10         7.00         0.00         0.50         0.00          0.00                   0.30         11.80                  2.50\n",
      "50%               1.00           1.88        10.00         0.50         0.50         2.05          0.00                   0.30         15.36                  2.50\n",
      "75%               1.00           3.40        15.50         2.50         0.50         3.16          0.00                   0.30         21.80                  2.50\n",
      "max               9.00     317,182.45   818,283.44        41.07         4.25       500.00        911.30                   0.30    818,286.74                  2.75\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the first DataFrame\n",
    "print(df3.head(3))\n",
    "\n",
    "# Display summary information about DataFrame\n",
    "print(df3.info())\n",
    "\n",
    "# Basic statistical details\n",
    "print(df3.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e916d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " VendorID                      0\n",
      "tpep_pickup_datetime          0\n",
      "tpep_dropoff_datetime         0\n",
      "passenger_count          278444\n",
      "trip_distance                 0\n",
      "RatecodeID               278444\n",
      "store_and_fwd_flag       278444\n",
      "PULocationID                  0\n",
      "DOLocationID                  0\n",
      "payment_type                  0\n",
      "fare_amount                   0\n",
      "extra                         0\n",
      "mta_tax                       0\n",
      "tip_amount                    0\n",
      "tolls_amount                  0\n",
      "improvement_surcharge         0\n",
      "total_amount                  0\n",
      "congestion_surcharge     278444\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_values3 = df3.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60317843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      " VendorID                 category\n",
      "tpep_pickup_datetime       object\n",
      "tpep_dropoff_datetime      object\n",
      "passenger_count           float64\n",
      "trip_distance             float64\n",
      "RatecodeID               category\n",
      "store_and_fwd_flag       category\n",
      "PULocationID             category\n",
      "DOLocationID             category\n",
      "payment_type             category\n",
      "fare_amount               float64\n",
      "extra                     float64\n",
      "mta_tax                   float64\n",
      "tip_amount                float64\n",
      "tolls_amount              float64\n",
      "improvement_surcharge     float64\n",
      "total_amount              float64\n",
      "congestion_surcharge      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of each column:\\n\", df3.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6605f0",
   "metadata": {},
   "source": [
    "### Partition 4 Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b8315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "0      2.0  10/28/2021 03:35:00 PM  10/28/2021 03:44:01 PM             1.00           1.80        1.0                  N        170.0         79.0          1.0         8.00   0.00     0.50        1.00          0.00                   0.30         12.30                  2.50\n",
      "1      2.0  10/28/2021 03:45:48 PM  10/28/2021 04:04:51 PM             1.00           1.45        1.0                  N         79.0        170.0          1.0        12.50   0.00     0.50        3.16          0.00                   0.30         18.96                  2.50\n",
      "2      1.0  10/28/2021 03:08:00 PM  10/28/2021 03:26:20 PM             2.00           1.70        1.0                  N        141.0        142.0          1.0        12.00   2.50     0.50        2.00          0.00                   0.30         17.30                  2.50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7223319 entries, 0 to 7223318\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   VendorID               category\n",
      " 1   tpep_pickup_datetime   object  \n",
      " 2   tpep_dropoff_datetime  object  \n",
      " 3   passenger_count        float64 \n",
      " 4   trip_distance          float64 \n",
      " 5   RatecodeID             category\n",
      " 6   store_and_fwd_flag     category\n",
      " 7   PULocationID           category\n",
      " 8   DOLocationID           category\n",
      " 9   payment_type           category\n",
      " 10  fare_amount            float64 \n",
      " 11  extra                  float64 \n",
      " 12  mta_tax                float64 \n",
      " 13  tip_amount             float64 \n",
      " 14  tolls_amount           float64 \n",
      " 15  improvement_surcharge  float64 \n",
      " 16  total_amount           float64 \n",
      " 17  congestion_surcharge   float64 \n",
      "dtypes: category(6), float64(10), object(2)\n",
      "memory usage: 716.4+ MB\n",
      "None\n",
      "       passenger_count  trip_distance  fare_amount        extra      mta_tax   tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
      "count     6,857,096.00   7,223,319.00 7,223,319.00 7,223,319.00 7,223,319.00 7,223,319.00  7,223,319.00           7,223,319.00  7,223,319.00          6,857,096.00\n",
      "mean              1.43           8.92        14.33         1.05         0.49         2.59          0.50                   0.30         20.91                  2.31\n",
      "std               1.01         885.08        13.31         1.26         0.08         3.10          1.98                   0.04         16.49                  0.70\n",
      "min               0.00           0.00      -700.00        -4.50        -0.55       -98.00        -51.00                  -0.30       -702.80                 -2.50\n",
      "25%               1.00           1.10         7.00         0.00         0.50         0.00          0.00                   0.30         12.25                  2.50\n",
      "50%               1.00           1.86        10.00         0.50         0.50         2.06          0.00                   0.30         15.95                  2.50\n",
      "75%               2.00           3.46        16.00         2.50         0.50         3.27          0.00                   0.30         22.55                  2.50\n",
      "max               9.00     351,613.36     3,009.00        30.50        38.80       999.99        800.07                   0.30      3,012.30                  2.50\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the first DataFrame\n",
    "print(df4.head(3))\n",
    "\n",
    "# Display summary information about DataFrame\n",
    "print(df4.info())\n",
    "\n",
    "# Basic statistical details\n",
    "print(df4.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e7e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " VendorID                      0\n",
      "tpep_pickup_datetime          0\n",
      "tpep_dropoff_datetime         0\n",
      "passenger_count          366223\n",
      "trip_distance                 0\n",
      "RatecodeID               366223\n",
      "store_and_fwd_flag       366223\n",
      "PULocationID                  0\n",
      "DOLocationID                  0\n",
      "payment_type                  0\n",
      "fare_amount                   0\n",
      "extra                         0\n",
      "mta_tax                       0\n",
      "tip_amount                    0\n",
      "tolls_amount                  0\n",
      "improvement_surcharge         0\n",
      "total_amount                  0\n",
      "congestion_surcharge     366223\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_values4 = df4.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521a3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      " VendorID                 category\n",
      "tpep_pickup_datetime       object\n",
      "tpep_dropoff_datetime      object\n",
      "passenger_count           float64\n",
      "trip_distance             float64\n",
      "RatecodeID               category\n",
      "store_and_fwd_flag       category\n",
      "PULocationID             category\n",
      "DOLocationID             category\n",
      "payment_type             category\n",
      "fare_amount               float64\n",
      "extra                     float64\n",
      "mta_tax                   float64\n",
      "tip_amount                float64\n",
      "tolls_amount              float64\n",
      "improvement_surcharge     float64\n",
      "total_amount              float64\n",
      "congestion_surcharge      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of each column:\\n\", df4.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cee753",
   "metadata": {},
   "source": [
    "## Summary of initial Exploration and Next Steps:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
