{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b7ed76",
   "metadata": {},
   "source": [
    "# Taxi Fare Prediction Modeling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Research Objective\n",
    "The primary objective of this study is to develop a predictive fare model using the comprehensive NYC yellow taxi trip dataset from 2023. The aim is to identify key fare determinants and leverage advanced machine learning techniques to create a model that can estimate taxi fares accurately. This model will then be adapted to propose a more structured and transparent fare system for Tbilisi, Georgia.\n",
    "\n",
    "### Summary of EDA Insights and Hypotheses\n",
    "From the exploratory data analysis, several key insights were derived:\n",
    "- The fare amount, trip distance, trip duration, speed, and tip amount distributions were highly right-skewed, indicating the need for transformations.\n",
    "- Fare amount had strong positive correlations with trip distance and trip duration.\n",
    "- Categorical variables such as time of day, day type, season, and holidays significantly impacted fare amounts.\n",
    "- Proper handling of outliers was crucial to prevent skewing model predictions.\n",
    "\n",
    "#### Hypotheses\n",
    "1. **Trip Distance and Duration:** Longer trips (both in terms of distance and duration) will result in higher fares.\n",
    "2. **Temporal Factors:** Taxi fares vary significantly by time of day, day of the week, and season, with peak times and special events (e.g., holidays) resulting in higher fares.\n",
    "3. **Speed:** Higher average speeds may correlate with higher fares due to longer distances covered in shorter times.\n",
    "4. **Tips:** Higher fares tend to receive higher tips.\n",
    "\n",
    "The modeling phase will test these hypotheses by evaluating the predictive power of these factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3016c4a",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Data Preparation\n",
    "The dataset used for modeling has been cleaned and preprocessed based on the insights from the EDA. Key steps include:\n",
    "- Log transformations to normalize skewed data.\n",
    "- Handling outliers using Z-score filtering.\n",
    "- Encoding categorical variables using one-hot encoding.\n",
    "- Scaling numerical features.\n",
    "- PCA analysis\n",
    "\n",
    "### Model Selection\n",
    "To build a robust fare prediction model, we will use both simple and complex machine learning models:\n",
    "1. **Simple Models:**\n",
    "   - Linear Regression\n",
    "2. **Complex Models:**\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Gradient Boosting Machines (GBM)\n",
    "   - XGBoost\n",
    "\n",
    "### Model Evaluation Metrics\n",
    "The performance of the models will be evaluated using the following metrics:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- R-squared (R²)\n",
    "\n",
    "These metrics will help in understanding the accuracy and reliability of the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10d4e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d04114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared dataset\n",
    "df = pd.read_parquet('modeling_dataset_v.0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c57713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>speed_mph</th>\n",
       "      <th>JFK_LGA_Pickup_Fee</th>\n",
       "      <th>General_Airport_Fee</th>\n",
       "      <th>log_fare_amount</th>\n",
       "      <th>log_trip_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_time_of_day</th>\n",
       "      <th>pickup_season</th>\n",
       "      <th>passenger_count_category</th>\n",
       "      <th>pickup_day_type</th>\n",
       "      <th>PUzone</th>\n",
       "      <th>PUborough</th>\n",
       "      <th>DOzone</th>\n",
       "      <th>DOborough</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19276873</th>\n",
       "      <td>19.1</td>\n",
       "      <td>20.366667</td>\n",
       "      <td>2.32</td>\n",
       "      <td>30.72</td>\n",
       "      <td>5.12</td>\n",
       "      <td>6.834697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000720</td>\n",
       "      <td>3.061832</td>\n",
       "      <td>...</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>autumn</td>\n",
       "      <td>low</td>\n",
       "      <td>weekday</td>\n",
       "      <td>Midtown Center</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>-0.464965</td>\n",
       "      <td>0.734329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25505385</th>\n",
       "      <td>17.7</td>\n",
       "      <td>18.933333</td>\n",
       "      <td>1.90</td>\n",
       "      <td>25.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.021127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.928524</td>\n",
       "      <td>2.992393</td>\n",
       "      <td>...</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>autumn</td>\n",
       "      <td>low</td>\n",
       "      <td>weekday</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Chelsea</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>-0.787874</td>\n",
       "      <td>0.722135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23056552</th>\n",
       "      <td>8.6</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>1.10</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.374302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.261763</td>\n",
       "      <td>2.297573</td>\n",
       "      <td>...</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>autumn</td>\n",
       "      <td>low</td>\n",
       "      <td>weekend</td>\n",
       "      <td>Manhattan Valley</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>-1.516879</td>\n",
       "      <td>0.074052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22171336</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.691450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.299246</td>\n",
       "      <td>...</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>autumn</td>\n",
       "      <td>low</td>\n",
       "      <td>weekday</td>\n",
       "      <td>Midtown Center</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Lincoln Square East</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>-1.523446</td>\n",
       "      <td>0.162344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241061</th>\n",
       "      <td>7.9</td>\n",
       "      <td>5.783333</td>\n",
       "      <td>1.07</td>\n",
       "      <td>14.88</td>\n",
       "      <td>2.98</td>\n",
       "      <td>11.100865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.186051</td>\n",
       "      <td>1.914469</td>\n",
       "      <td>...</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>autumn</td>\n",
       "      <td>low</td>\n",
       "      <td>weekday</td>\n",
       "      <td>Upper West Side North</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan Valley</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>-1.352724</td>\n",
       "      <td>-0.467095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount  trip_duration  trip_distance  total_amount  tip_amount  \\\n",
       "19276873         19.1      20.366667           2.32         30.72        5.12   \n",
       "25505385         17.7      18.933333           1.90         25.20        3.50   \n",
       "23056552          8.6       8.950000           1.10         12.10        2.00   \n",
       "22171336         10.0       8.966667           1.00         16.00        2.00   \n",
       "25241061          7.9       5.783333           1.07         14.88        2.98   \n",
       "\n",
       "          speed_mph  JFK_LGA_Pickup_Fee  General_Airport_Fee  log_fare_amount  \\\n",
       "19276873   6.834697                 0.0                  0.0         3.000720   \n",
       "25505385   6.021127                 0.0                  0.0         2.928524   \n",
       "23056552   7.374302                 0.0                  0.0         2.261763   \n",
       "22171336   6.691450                 0.0                  0.0         2.397895   \n",
       "25241061  11.100865                 0.0                  0.0         2.186051   \n",
       "\n",
       "          log_trip_duration  ...  pickup_time_of_day  pickup_season  \\\n",
       "19276873           3.061832  ...           afternoon         autumn   \n",
       "25505385           2.992393  ...           afternoon         autumn   \n",
       "23056552           2.297573  ...           afternoon         autumn   \n",
       "22171336           2.299246  ...           afternoon         autumn   \n",
       "25241061           1.914469  ...           afternoon         autumn   \n",
       "\n",
       "          passenger_count_category  pickup_day_type                 PUzone  \\\n",
       "19276873                       low          weekday         Midtown Center   \n",
       "25505385                       low          weekday           Midtown East   \n",
       "23056552                       low          weekend       Manhattan Valley   \n",
       "22171336                       low          weekday         Midtown Center   \n",
       "25241061                       low          weekday  Upper West Side North   \n",
       "\n",
       "          PUborough               DOzone  DOborough      PCA1      PCA2  \n",
       "19276873  Manhattan         East Village  Manhattan -0.464965  0.734329  \n",
       "25505385  Manhattan         East Chelsea  Manhattan -0.787874  0.722135  \n",
       "23056552  Manhattan    East Harlem South  Manhattan -1.516879  0.074052  \n",
       "22171336  Manhattan  Lincoln Square East  Manhattan -1.523446  0.162344  \n",
       "25241061  Manhattan     Manhattan Valley  Manhattan -1.352724 -0.467095  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a2d5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2805668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b2a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount                  float64\n",
       "trip_duration                float64\n",
       "trip_distance                float64\n",
       "total_amount                 float64\n",
       "tip_amount                   float64\n",
       "speed_mph                    float64\n",
       "JFK_LGA_Pickup_Fee           float64\n",
       "General_Airport_Fee          float64\n",
       "log_fare_amount              float64\n",
       "log_trip_duration            float64\n",
       "log_trip_distance            float64\n",
       "log_tip_amount               float64\n",
       "is_holiday                     int64\n",
       "payment_type                   int64\n",
       "pickup_time_of_day          category\n",
       "pickup_season               category\n",
       "passenger_count_category    category\n",
       "pickup_day_type             category\n",
       "PUzone                      category\n",
       "PUborough                   category\n",
       "DOzone                      category\n",
       "DOborough                   category\n",
       "PCA1                         float64\n",
       "PCA2                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70646fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratify_col\n",
      "spring_evening_weekday_Manhattan_Manhattan      162096\n",
      "spring_afternoon_weekday_Manhattan_Manhattan    152673\n",
      "autumn_evening_weekday_Manhattan_Manhattan      149395\n",
      "autumn_afternoon_weekday_Manhattan_Manhattan    140089\n",
      "winter_afternoon_weekday_Manhattan_Manhattan    139463\n",
      "                                                 ...  \n",
      "autumn_night_weekend_Unknown_EWR                     1\n",
      "autumn_afternoon_weekday_EWR_EWR                     1\n",
      "autumn_evening_weekday_Unknown_EWR                   1\n",
      "spring_night_weekday_Staten Island_Queens            1\n",
      "winter_night_weekday_Unknown_EWR                     1\n",
      "Name: count, Length: 1050, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a combined column for stratification\n",
    "df['stratify_col'] = df['pickup_season'].astype(str) + '_' + df['pickup_time_of_day'].astype(str) + '_' + df['pickup_day_type'].astype(str) + '_' + df['PUborough'].astype(str) + '_' + df['DOborough'].astype(str)\n",
    "\n",
    "# Check the distribution of the combined stratification column\n",
    "stratify_counts = df['stratify_col'].value_counts()\n",
    "print(stratify_counts)\n",
    "\n",
    "# Filter out classes with very few samples\n",
    "min_class_size = 5  # Define a minimum class size\n",
    "filtered_classes = stratify_counts[stratify_counts >= min_class_size].index\n",
    "df_filtered = df[df['stratify_col'].isin(filtered_classes)]\n",
    "\n",
    "# Perform stratified sampling on the filtered dataset\n",
    "df_sample, _ = train_test_split(df_filtered, test_size=0.9, stratify=df_filtered['stratify_col'], random_state=42)\n",
    "\n",
    "# Drop the stratify column\n",
    "df_sample = df_sample.drop(columns=['stratify_col'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4566aedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2805668\n",
      "280513\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b690c1e",
   "metadata": {},
   "source": [
    "For the modeling purposes we performed stratified sampling to ensure that all the categorical features remain intact and we have a model that can give us insights based on the categorical variables as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707638ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and encoding\n",
    "features = df_sample[['PCA1', 'PCA2', 'is_holiday', 'pickup_time_of_day', 'pickup_season', 'passenger_count_category', 'pickup_day_type', 'PUzone', 'PUborough', 'DOzone', 'DOborough']]\n",
    "target = df_sample['fare_amount']\n",
    "\n",
    "categorical_features = ['is_holiday', 'pickup_time_of_day', 'pickup_season', 'passenger_count_category', 'pickup_day_type', 'PUzone', 'PUborough', 'DOzone', 'DOborough']\n",
    "encoder = ColumnTransformer(transformers=[('cat', OneHotEncoder(drop='first'), categorical_features)], remainder='passthrough')\n",
    "\n",
    "X = encoder.fit_transform(features)\n",
    "y = target.values\n",
    "\n",
    "# Reduce the number of features using SelectKBest\n",
    "X_new = SelectKBest(f_regression, k=10).fit_transform(X, y)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the data for KNN and SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_train_lr = linear_model.predict(X_train)\n",
    "y_pred_val_lr = linear_model.predict(X_val)\n",
    "print(\"Linear Regression Performance\")\n",
    "print(\"Training MAE:\", mean_absolute_error(y_train, y_pred_train_lr))\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_lr))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_lr))\n",
    "\n",
    "# Decision Tree with Grid Search for parameter tuning\n",
    "param_grid_dt = {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "dt_grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=3, n_jobs=-1)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "best_dt_model = dt_grid_search.best_estimator_\n",
    "y_pred_val_dt = best_dt_model.predict(X_val)\n",
    "print(\"Decision Tree Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_dt))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_dt))\n",
    "\n",
    "# Random Forest with Grid Search for parameter tuning\n",
    "param_grid_rf = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "y_pred_val_rf = best_rf_model.predict(X_val)\n",
    "print(\"Random Forest Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_rf))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_rf))\n",
    "\n",
    "# Gradient Boosting with early stopping\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, validation_fraction=0.1, n_iter_no_change=10)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_val_gb = gb_model.predict(X_val)\n",
    "print(\"Gradient Boosting Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_gb))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_gb))\n",
    "\n",
    "# XGBoost with Grid Search for parameter tuning\n",
    "param_grid_xgb = {'n_estimators': [50, 100], 'max_depth': [3, 6, 10], 'learning_rate': [0.01, 0.1]}\n",
    "xgb_grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid_xgb, cv=3, n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "y_pred_val_xgb = best_xgb_model.predict(X_val)\n",
    "print(\"XGBoost Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_xgb))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_xgb))\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_val_knn = knn_model.predict(X_val_scaled)\n",
    "print(\"KNN Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_knn))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_knn))\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_val_svm = svm_model.predict(X_val_scaled)\n",
    "print(\"SVM Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_svm))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_svm))\n",
    "\n",
    "# Summarize Model Performance\n",
    "models = ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'KNN', 'SVM']\n",
    "val_mae = [\n",
    "    mean_absolute_error(y_val, y_pred_val_lr),\n",
    "    mean_absolute_error(y_val, y_pred_val_dt),\n",
    "    mean_absolute_error(y_val, y_pred_val_rf),\n",
    "    mean_absolute_error(y_val, y_pred_val_gb),\n",
    "    mean_absolute_error(y_val, y_pred_val_xgb),\n",
    "    mean_absolute_error(y_val, y_pred_val_knn),\n",
    "    mean_absolute_error(y_val, y_pred_val_svm)\n",
    "]\n",
    "val_r2 = [\n",
    "    r2_score(y_val, y_pred_val_lr),\n",
    "    r2_score(y_val, y_pred_val_dt),\n",
    "    r2_score(y_val, y_pred_val_rf),\n",
    "    r2_score(y_val, y_pred_val_gb),\n",
    "    r2_score(y_val, y_pred_val_xgb),\n",
    "    r2_score(y_val, y_pred_val_knn),\n",
    "    r2_score(y_val, y_pred_val_svm)\n",
    "]\n",
    "\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Validation MAE': val_mae,\n",
    "    'Validation R²': val_r2\n",
    "})\n",
    "\n",
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37635a",
   "metadata": {},
   "source": [
    "# Preparation For Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c68373b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and encoding\n",
    "features = df_sample[['PCA1', 'PCA2', 'is_holiday', 'pickup_time_of_day', 'pickup_season', 'passenger_count_category', 'pickup_day_type', 'PUzone', 'PUborough', 'DOzone', 'DOborough']]\n",
    "target = df_sample['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28843bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['is_holiday', 'pickup_time_of_day', 'pickup_season', 'passenger_count_category', 'pickup_day_type', 'PUzone', 'PUborough', 'DOzone', 'DOborough']\n",
    "encoder = ColumnTransformer(transformers=[('cat', OneHotEncoder(drop='first'), categorical_features)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb01c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoder.fit_transform(features)\n",
    "y = target.values\n",
    "\n",
    "# Reduce the number of features using SelectKBest\n",
    "X_new = SelectKBest(f_regression, k=10).fit_transform(X, y)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "269a0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data for KNN and SVM\n",
    "scaler = StandardScaler(with_mean= False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ce289",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59c3f359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance\n",
      "Training MAE: 2.697683248247949\n",
      "Validation MAE: 2.6931883885075365\n",
      "Validation R²: 0.944835876489503\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model: Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_val = linear_model.predict(X_val)\n",
    "\n",
    "print(\"Linear Regression Performance\")\n",
    "print(\"Training MAE:\", mean_absolute_error(y_train, y_pred_train))\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ffc59",
   "metadata": {},
   "source": [
    "\n",
    "### Linear Regression Model\n",
    "\n",
    "**Performance Metrics:**\n",
    "- **Training MAE:** 2.70\n",
    "- **Validation MAE:** 2.69\n",
    "- **Validation R²:** 0.9448\n",
    "\n",
    "**Interpretation:**\n",
    "1. **Mean Absolute Error (MAE):**\n",
    "   - The average absolute error in fare prediction is approximately $2.70 on the training data and $2.69 on the validation data. The closeness of these values indicates that the model is not overfitting and generalizes well to unseen data.\n",
    "2. **R-squared (R²):**\n",
    "   - The R² value of 0.9448 indicates that approximately 94.48% of the variance in taxi fares can be explained by the model. This high R² value suggests that the linear regression model fits the data well.\n",
    "\n",
    "**Conclusion:**\n",
    "- The linear regression model performs well with a high R² value and low MAE, indicating strong predictive capability for the given features. However, it is a simple model and may not capture complex, non-linear relationships in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da61d4",
   "metadata": {},
   "source": [
    "## Complex Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "550d1294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance\n",
      "Validation MAE: 2.3716119571271497\n",
      "Validation R²: 0.9545403292306762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decision Tree with Grid Search for parameter tuning\n",
    "param_grid_dt = {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "dt_grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=3, n_jobs=-1)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "best_dt_model = dt_grid_search.best_estimator_\n",
    "y_pred_val_dt = best_dt_model.predict(X_val)\n",
    "print(\"Decision Tree Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_dt))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9296ed",
   "metadata": {},
   "source": [
    "### Decision Tree Model\n",
    "\n",
    "**Performance Metrics:**\n",
    "- **Validation MAE:** 2.37\n",
    "- **Validation R²:** 0.9545\n",
    "\n",
    "**Interpretation:**\n",
    "1. **Mean Absolute Error (MAE):**\n",
    "   - The average absolute error in fare prediction is approximately $2.37 on the validation data. This is slightly lower than the MAE of the linear regression model, indicating better predictive accuracy.\n",
    "2. **R-squared (R²):**\n",
    "   - The R² value of 0.9545 indicates that approximately 95.45% of the variance in taxi fares can be explained by the decision tree model. This is higher than the R² value for the linear regression model, suggesting that the decision tree captures more variability in the data.\n",
    "\n",
    "**Conclusion:**\n",
    "- The decision tree model performs better than the linear regression model in terms of both MAE and R². It captures more complex relationships between the features and the target variable. However, decision trees can be prone to overfitting, so it is essential to validate the model on unseen data and potentially prune the tree or limit its depth to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "136dbdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Performance\n",
      "Validation MAE: 2.41214002650482\n",
      "Validation R²: 0.9550262508155019\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting with early stopping\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, validation_fraction=0.1, n_iter_no_change=10)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_val_gb = gb_model.predict(X_val)\n",
    "print(\"Gradient Boosting Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_gb))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c8ee9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance\n",
      "Validation MAE: 2.3678238791443933\n",
      "Validation R²: 0.9528451666259213\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search for parameter tuning\n",
    "param_grid_xgb = {'n_estimators': [50, 100], 'max_depth': [3, 6, 10], 'learning_rate': [0.01, 0.1]}\n",
    "xgb_grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid_xgb, cv=3, n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "y_pred_val_xgb = best_xgb_model.predict(X_val)\n",
    "print(\"XGBoost Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_xgb))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with Randomized Search for parameter tuning using a smaller sample and fewer folds\n",
    "param_dist_rf = {'n_estimators': [10, 50], 'max_depth': [10, 20], 'min_samples_split': [2, 5]}\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
    "rf_random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_distributions=param_dist_rf, n_iter=10, cv=2, n_jobs=-1, random_state=42)\n",
    "rf_random_search.fit(X_train_sample, y_train_sample)\n",
    "best_rf_model = rf_random_search.best_estimator_\n",
    "final_rf_model = RandomForestRegressor(**best_rf_model.get_params())\n",
    "final_rf_model.fit(X_train, y_train)\n",
    "y_pred_val_rf = final_rf_model.predict(X_val)\n",
    "print(\"Random Forest Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_rf))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f06956a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/8tkcz58x0md0_v7fj12j6ht80000gn/T/ipykernel_2648/1713529712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred_val_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNN Performance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation MAE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_val_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m     \"\"\"\n\u001b[0;32m--> 858\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_val_knn = knn_model.predict(X_val_scaled)\n",
    "print(\"KNN Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_knn))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_val_svm = svm_model.predict(X_val_scaled)\n",
    "print(\"SVM Performance\")\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_svm))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network (MLP)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Predict on training and validation data\n",
    "y_pred_train_nn = model.predict(X_train)\n",
    "y_pred_val_nn = model.predict(X_val)\n",
    "\n",
    "print(\"Neural Network Performance\")\n",
    "print(\"Training MAE:\", mean_absolute_error(y_train, y_pred_train_nn))\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, y_pred_val_nn))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_pred_val_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'KNN', 'SVM', 'Neural Network']\n",
    "train_mae = [\n",
    "    mean_absolute_error(y_train, linear_model.predict(X_train)),\n",
    "    mean_absolute_error(y_train, dt_model.predict(X_train)),\n",
    "    mean_absolute_error(y_train, rf_model.predict(X_train)),\n",
    "    mean_absolute_error(y_train, gb_model.predict(X_train)),\n",
    "    mean_absolute_error(y_train, xgb_model.predict(X_train)),\n",
    "    mean_absolute_error(y_train, knn_model.predict(X_train_scaled)),\n",
    "    mean_absolute_error(y_train, svm_model.predict(X_train_scaled)),\n",
    "    mean_absolute_error(y_train, model.predict(X_train))\n",
    "]\n",
    "val_mae = [\n",
    "    mean_absolute_error(y_val, linear_model.predict(X_val)),\n",
    "    mean_absolute_error(y_val, dt_model.predict(X_val)),\n",
    "    mean_absolute_error(y_val, rf_model.predict(X_val)),\n",
    "    mean_absolute_error(y_val, gb_model.predict(X_val)),\n",
    "    mean_absolute_error(y_val, xgb_model.predict(X_val)),\n",
    "    mean_absolute_error(y_val, knn_model.predict(X_val_scaled)),\n",
    "    mean_absolute_error(y_val, svm_model.predict(X_val_scaled)),\n",
    "    mean_absolute_error(y_val, model.predict(X_val))\n",
    "]\n",
    "val_r2 = [\n",
    "    r2_score(y_val, linear_model.predict(X_val)),\n",
    "    r2_score(y_val, dt_model.predict(X_val)),\n",
    "    r2_score(y_val, rf_model.predict(X_val)),\n",
    "    r2_score(y_val, gb_model.predict(X_val)),\n",
    "    r2_score(y_val, xgb_model.predict(X_val)),\n",
    "    r2_score(y_val, knn_model.predict(X_val_scaled)),\n",
    "    r2_score(y_val, svm_model.predict(X_val_scaled)),\n",
    "    r2_score(y_val, model.predict(X_val))\n",
    "]\n",
    "\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Training MAE': train_mae,\n",
    "    'Validation MAE': val_mae,\n",
    "    'Validation R²': val_r2\n",
    "})\n",
    "\n",
    "print(performance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
